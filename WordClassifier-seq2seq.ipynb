{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network - Word Classification\n",
    "## Using Seq2Seq model\n",
    "Implemented in TensorFlow. Using bidirectual RNN as encoder and decoder implemented as tf.nn.raw_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 1.2.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell_impl import LSTMCell, LSTMStateTuple\n",
    "import time\n",
    "\n",
    "from ocr.datahelpers import loadWordsData, correspondingShuffle\n",
    "from ocr.mlhelpers import TrainingPlot\n",
    "\n",
    "%matplotlib notebook\n",
    "# Increase size of images\n",
    "plt.rcParams['figure.figsize'] = (9.0, 5.0)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "print('Tensorflow', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading words...\n",
      "Number of Images: 1166\n"
     ]
    }
   ],
   "source": [
    "images, labels = loadWordsData(['data/words/', 'data/words_nolines/'],\n",
    "                               loadGaplines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chars: 82\n"
     ]
    }
   ],
   "source": [
    "CHARS = ['A', 'a', 'Á', 'á', 'B', 'b', 'C', 'c', 'Č', 'č',\n",
    "         'D', 'd', 'Ď', 'ď', 'E', 'e', 'É', 'é', 'Ě', 'ě',\n",
    "         'F', 'f', 'G', 'g', 'H', 'h', 'I', 'i', 'Í', 'í',         \n",
    "         'J', 'j', 'K', 'k', 'L', 'l', 'M', 'm', 'N', 'n',\n",
    "         'Ň', 'ň', 'O', 'o', 'Ó', 'ó', 'P', 'p', 'Q', 'q',\n",
    "         'R', 'r', 'Ř', 'ř', 'S', 's', 'Š', 'š', 'T', 't',\n",
    "         'Ť', 'ť', 'U', 'u', 'Ú', 'ú', 'Ů', 'ů', 'V', 'v',\n",
    "         'W', 'w', 'X', 'x', 'Y', 'y', 'Ý', 'ý', 'Z', 'z',\n",
    "         'Ž', 'ž']\n",
    "\n",
    "char_size = len(CHARS)\n",
    "print(\"Number of chars:\", char_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0   # Padding\n",
    "EOS = 1   # End of seq\n",
    "\n",
    "num_buckets = 5\n",
    "slider_size = (60, 30)\n",
    "N_INPUT = 30*60               # Size of sequence input vector\n",
    "vocab_size = char_size + 2    # Number of different chars + <PAD> and <EOS>\n",
    "input_embedding_size = 40     # Size of vector for embedding chars2vec\n",
    "\n",
    "encoder_hidden_units = 60\n",
    "decoder_hidden_units = 4 * encoder_hidden_units  # 4* is neccesary due to the concat (probably)\n",
    "final_hidden_units = 2 * encoder_hidden_units\n",
    "\n",
    "learning_rate = 1e-4\n",
    "train_per = 0.8               # Percentage of training data\n",
    "\n",
    "TRAIN_STEPS = 1           # Number of training steps!\n",
    "TEST_ITER = 150\n",
    "LOSS_ITER = 50\n",
    "SAVE_ITER = 2000\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 1000                  # Number of batches in epoch - not accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 932\n",
      "Testing images: 234\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data for later splitting\n",
    "images, labels = correspondingShuffle(images, labels)\n",
    "\n",
    "idxs = [i+2 for i in range(char_size)]\n",
    "idx_to_chars = dict(zip(idxs, CHARS))\n",
    "chars_to_idx = dict(zip(CHARS, idxs))\n",
    "\n",
    "labels_idx = np.empty(len(labels), dtype=object)\n",
    "for i, label in enumerate(labels):\n",
    "    labels_idx[i] = [chars_to_idx[c] for c in label]\n",
    "\n",
    "# Split data on train and test dataset\n",
    "div = int(0.80 * len(images))\n",
    "\n",
    "trainImages = images[0:div]\n",
    "testImages = images[div:]\n",
    "\n",
    "trainLabels_idx = labels_idx[0:div]\n",
    "testLabels_idx = labels_idx[div:]\n",
    "\n",
    "print(\"Training images:\", div)\n",
    "print(\"Testing images:\", len(images) - div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterator created.\n",
      "Iterator created.\n"
     ]
    }
   ],
   "source": [
    "class BucketDataIterator():\n",
    "    \"\"\" Iterator for feeding seq2seq model during training \"\"\"\n",
    "    def __init__(self, images, targets, num_buckets=5, slider=(60, 30)):\n",
    "        # First PADDING of images to slider size ( -(a // b) ==  ceil(a/b))\n",
    "        self.slider = slider\n",
    "        for i in images:\n",
    "            i.resize((i.shape[0], -(-i.shape[1] // slider[1]) * slider[1]),\n",
    "                     refcheck=False)\n",
    "        in_length = [image.shape[1]//slider[1] for image in images]\n",
    "        # Split images to sequence of vectors\n",
    "        imgseq = np.empty(len(images), dtype=object)\n",
    "        for i, img in enumerate(images):\n",
    "            imgseq[i] = [img[:, loc*slider[1]:(loc+1)*slider[1]].flatten()\n",
    "                         for loc in range(in_length[i])]\n",
    "        \n",
    "        # Add EOS symbol to each output sequence\n",
    "        for t in targets:\n",
    "            t.append(EOS)           \n",
    "        # Create pandas dataFrame and sort it by images width (length) \n",
    "        self.dataFrame = pd.DataFrame({'in_length': in_length,\n",
    "                                       'out_length': [len(t) for t in targets],\n",
    "                                       'images': imgseq,\n",
    "                                       'targets': targets\n",
    "                                      }).sort_values('in_length').reset_index(drop=True)\n",
    "\n",
    "        bsize = int(len(images) / num_buckets)\n",
    "        self.num_buckets = num_buckets\n",
    "        \n",
    "        # Create buckets by slicing parts by indexes\n",
    "        self.buckets = []\n",
    "        for bucket in range(num_buckets-1):\n",
    "            self.buckets.append(self.dataFrame.iloc[bucket*bsize:(bucket+1)*bsize-1])\n",
    "        self.buckets.append(self.dataFrame.iloc[num_buckets-1*bsize:])        \n",
    "        \n",
    "        self.buckets_size = [len(bucket) for bucket in self.buckets]\n",
    "\n",
    "        # cursor[i] will be the cursor for the ith bucket\n",
    "        self.cursor = np.array([0] * num_buckets)\n",
    "        self.bucket_order = np.random.permutation(num_buckets)\n",
    "        self.bucket_cursor = 0\n",
    "        self.shuffle()\n",
    "        print(\"Iterator created.\")\n",
    "\n",
    "    def shuffle(self, idx=None):\n",
    "        \"\"\" Shuffle idx bucket or each bucket separately \"\"\"\n",
    "        for i in [idx] if idx is not None else range(self.num_buckets):\n",
    "            self.buckets[i] = self.buckets[i].sample(frac=1).reset_index(drop=True)\n",
    "            self.cursor[i] = 0\n",
    "\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"\n",
    "        Creates next training batch of size: batch_size\n",
    "        Retruns: image seq, letter seq,\n",
    "                 image seq lengths, letter seq lengths\n",
    "        \"\"\"\n",
    "        i_bucket = self.bucket_order[self.bucket_cursor]\n",
    "        # Increment cursor and shuffle in case of new round\n",
    "        self.bucket_cursor = (self.bucket_cursor + 1) % self.num_buckets\n",
    "        if self.bucket_cursor == 0:\n",
    "            self.bucket_order = np.random.permutation(self.num_buckets)\n",
    "            \n",
    "        if self.cursor[i_bucket] + batch_size > self.buckets_size[i_bucket]:\n",
    "            self.shuffle(i_bucket)\n",
    "\n",
    "        # Handle too big batch sizes\n",
    "        if (batch_size > self.buckets_size[i_bucket]):\n",
    "            batch_size = self.buckets_size[i_bucket]\n",
    "\n",
    "        res = self.buckets[i_bucket].iloc[self.cursor[i_bucket]:\n",
    "                                          self.cursor[i_bucket]+batch_size]\n",
    "        self.cursor[i_bucket] += batch_size\n",
    "\n",
    "        # PAD input sequence and output\n",
    "        # Pad sequences with <PAD> to same length\n",
    "        input_max = max(res['in_length'])\n",
    "        output_max = max(res['out_length'])\n",
    "        assert input_max + 10 >= output_max   # In order to make it work\n",
    "        \n",
    "        input_seq = np.zeros((batch_size, input_max, N_INPUT), dtype=np.float32)\n",
    "        for i, img in enumerate(res['images']):\n",
    "            input_seq[i][:res['in_length'].values[i]] = img\n",
    "        input_seq = input_seq.swapaxes(0, 1)\n",
    "        \n",
    "        # Need to pad according to the input size\n",
    "        targets = np.zeros([batch_size, input_max+10], dtype=np.int32)\n",
    "        for i, target in enumerate(targets):\n",
    "            target[:res['out_length'].values[i]] = res['targets'].values[i]\n",
    "        targets = targets.swapaxes(0, 1)\n",
    "        \n",
    "        return input_seq, targets, res['in_length'].values, res['out_length'].values\n",
    "    \n",
    "    def next_feed(self, size):\n",
    "        \"\"\" Create feed directly for model training \"\"\"\n",
    "        (encoder_inputs_,\n",
    "         decoder_targets_,\n",
    "         encoder_input_lengths_,\n",
    "         _) = self.next_batch(size)\n",
    "        return {\n",
    "            encoder_inputs: encoder_inputs_,\n",
    "            encoder_inputs_length: encoder_input_lengths_,\n",
    "            decoder_targets: decoder_targets_\n",
    "        }\n",
    "\n",
    "\n",
    "# Create iterator for feeding RNN\n",
    "# Create only once, it modifies: labels_idx\n",
    "train_iterator = BucketDataIterator(trainImages, trainLabels_idx, num_buckets, slider_size)\n",
    "test_iterator = BucketDataIterator(testImages, testLabels_idx, num_buckets, slider_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input placehodlers\n",
    "# N_INPUT -> size of vector representing one image in sequence\n",
    "# Encoder inputs shape (max_seq_length, batch_size, vec_size)\n",
    "encoder_inputs = tf.placeholder(shape=(None, None, N_INPUT),\n",
    "                                dtype=tf.float32,\n",
    "                                name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None),\n",
    "                                       dtype=tf.int32,\n",
    "                                       name='encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                 dtype=tf.int32,\n",
    "                                 name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly initialized embedding matrix, for characters embedding in decoder\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size,\n",
    "                                            input_embedding_size],\n",
    "                                           -1.0,\n",
    "                                           1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_cell_fw = LSTMCell(num_units=encoder_hidden_units,\n",
    "                       state_is_tuple=True)\n",
    "enc_cell_bw = LSTMCell(num_units=encoder_hidden_units,\n",
    "                       state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bidirectional RNN, gibe fw and bw outputs separately\n",
    "((fw_outputs, bw_outputs),\n",
    " (fw_final_state, bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw = enc_cell_fw,\n",
    "                                    cell_bw = enc_cell_bw,\n",
    "                                    inputs = encoder_inputs,\n",
    "                                    sequence_length = encoder_inputs_length,\n",
    "                                    dtype = tf.float32,\n",
    "                                    time_major = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenates tensors along one dimension.\n",
    "encoder_outputs = tf.concat((fw_outputs, bw_outputs), 2)\n",
    "\n",
    "#TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=tf.concat((fw_final_state.c,\n",
    "                 bw_final_state.c), 1),\n",
    "    h=tf.concat((fw_final_state.h,\n",
    "                 bw_final_state.h), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(num_units=final_hidden_units,\n",
    "                        state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_time, batch_size, _ = tf.unstack(tf.shape(encoder_inputs))\n",
    "# +9 additional steps, +1 leading <EOS> token for decoder inputs\n",
    "decoder_lengths = encoder_inputs_length + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weights and bias for output\n",
    "# W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "# b = tf.variable(tf.zeros([vocab_size]), dtype=tf.float32)\n",
    "\n",
    "W = {'score': tf.Variable(tf.truncated_normal(shape=[final_hidden_units, final_hidden_units]),\n",
    "                          dtype=tf.float32,\n",
    "                          name='weight_score'),\n",
    "     'hdash': tf.Variable(tf.truncated_normal(shape=[decoder_hidden_units, decoder_hidden_units]),\n",
    "                          dtype=tf.float32,\n",
    "                          name='weight_hdash'),\n",
    "     'decoder': tf.Variable(tf.truncated_normal(shape=[decoder_hidden_units, vocab_size]),\n",
    "                            dtype=tf.float32,\n",
    "                            name='weight_decoder')}\n",
    "\n",
    "b = {'hdash': tf.Variable(tf.constant(0.1, shape=[decoder_hidden_units,]),\n",
    "                          dtype=tf.float32,\n",
    "                          name='bias_hdash'),\n",
    "     'decoder': tf.Variable(tf.constant(0.1, shape=[vocab_size,]),\n",
    "                            dtype=tf.float32,\n",
    "                            name='bias_decoder')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prapare PAD and EOS slices\n",
    "# Expected values due to tf.zeros and tf.ones\n",
    "assert EOS == 1 and PAD == 0\n",
    "\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial loop function when: time == 0\n",
    "def loop_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # All false\n",
    "    initial_input = eos_step_embedded # EOS is used also as starting input\n",
    "    initial_cell_state = encoder_final_state # Starting with encoder final state\n",
    "    initial_cell_output = None\n",
    "    initial_loop_state = None\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transition loop function when: time > 0\n",
    "def loop_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "    def get_next_input():\n",
    "        # Feeding previous output as next input of RNN\n",
    "        # output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        # prediction = tf.argmax(output_logits, axis=1)\n",
    "        # next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        #        \n",
    "        # return next_input\n",
    "        \n",
    "        prev_out_with_weights = tf.matmul(previous_output, W['score'], name='prev-score')\n",
    "        prev_out_with_weights = tf.reshape(prev_out_with_weights, [-1, final_hidden_units, 1])\n",
    "\n",
    "        score = tf.matmul(tf.transpose(encoder_outputs, [1, 0, 2]), prev_out_with_weights, name='enc-prev')\n",
    "        score = tf.reshape(score, [-1, encoder_max_time])\n",
    "        \n",
    "        attention = tf.nn.softmax(score)\n",
    "        attention = tf.reshape(attention, [-1, 1, encoder_max_time])\n",
    "        \n",
    "        ct = tf.matmul(attention, tf.transpose(encoder_outputs, [1, 0, 2]), name='att-enc')\n",
    "        ct = tf.reshape(ct, [-1, final_hidden_units])\n",
    "        \n",
    "        ctht = tf.concat((ct, previous_output), 1)\n",
    "        ht_dash = tf.nn.tanh(tf.add(tf.matmul(ctht, W['hdash'], name='ctht-hdash'), b['hdash']))\n",
    "        pred = tf.nn.softmax(tf.add(tf.matmul(ctht, W['decoder'], name='ctht-dec'), b['decoder']))\n",
    "        \n",
    "        prediction = tf.argmax(pred, axis=1)\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    # Defining if corresponding sequence has ended\n",
    "    elements_finished = (time >= decoder_lengths)\n",
    "    finished = tf.reduce_all(elements_finished) # -> boolean scalar\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    \n",
    "    # Set previous to current\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "\n",
    "    return (elements_finished, \n",
    "            input,\n",
    "            state,\n",
    "            output,\n",
    "            loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:    # time == 0\n",
    "        return loop_initial()\n",
    "    else:\n",
    "        return loop_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "\n",
    "decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "\n",
    "decoder_prev_out_with_weights = tf.matmul(decoder_outputs_flat,W['score'])\n",
    "decoder_prev_out_with_weights = tf.reshape(decoder_prev_out_with_weights,[-1,decoder_max_steps,final_hidden_units])\n",
    "encoder_outputs_new = tf.reshape(encoder_outputs,[-1,final_hidden_units,encoder_max_time])\n",
    "decoder_score = tf.matmul(decoder_prev_out_with_weights,encoder_outputs_new)\n",
    "decoder_attention = tf.nn.softmax(decoder_score)\n",
    "encoder_outputs_new = tf.reshape(encoder_outputs,[-1,encoder_max_time,final_hidden_units])\n",
    "decoder_ct = tf.matmul(decoder_attention,encoder_outputs_new)\n",
    "decoder_outputs_flat_new = tf.reshape(decoder_outputs_flat,[-1,decoder_max_steps,decoder_dim])\n",
    "decoder_ctht = tf.concat((decoder_ct,decoder_outputs_flat_new),2)\n",
    "decoder_ctht = tf.reshape(decoder_ctht,[-1,decoder_hidden_units])\n",
    "decoder_ctht_logits = tf.add(tf.matmul(decoder_ctht,W['hdash']),b['hdash'])\n",
    "decoder_ctht_logits = tf.reshape(decoder_ctht_logits,[-1,decoder_max_steps,decoder_hidden_units])\n",
    "decoder_ht_dash = tf.nn.tanh(decoder_ctht_logits)\n",
    "decoder_ht_dash = tf.reshape(decoder_ht_dash,[-1,decoder_hidden_units])\n",
    "decoder_ht_dash_logits = tf.add(tf.matmul(decoder_ht_dash,W['decoder']),b['decoder'])\n",
    "decoder_ht_dash_logits = tf.reshape(decoder_ht_dash_logits,[decoder_max_steps, -1, vocab_size])\n",
    "decoder_pred = tf.nn.softmax(decoder_ht_dash_logits)\n",
    "decoder_pred_prediction = tf.argmax(decoder_pred,axis=2)\n",
    "# decoder_pred_prediction = tf.reshape(decoder_pred_prediction,[-1,decoder_max_steps])\n",
    "\n",
    "decoder_logits = decoder_ht_dash_logits\n",
    "decoder_prediction = decoder_pred_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Reduces dimensionality\n",
    "# decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "# decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "# # Pass flattened tensor through decoder\n",
    "# decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "# decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))\n",
    "# # Final prediction\n",
    "# decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross entropy loss\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Evaluate model\n",
    "correct_prediction = tf.equal(decoder_prediction,\n",
    "                              tf.cast(decoder_targets, tf.int64), name='Corr-pred')\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"900\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 - loss: 26.12949\n",
      "    input     > [48 53 45 35 45 49  1  0  0  0  0  0  0  0]\n",
      "    predicted > [66 66 26 28 56 30 30 60  5  2 13 64 64 19]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# Creat plot for live stats ploting\n",
    "trainPlot = TrainingPlot(TRAIN_STEPS, TEST_ITER, LOSS_ITER)\n",
    "\n",
    "try:\n",
    "    for i_batch in range(TRAIN_STEPS):\n",
    "        fd = train_iterator.next_feed(BATCH_SIZE)\n",
    "        train_step.run(fd)\n",
    "        \n",
    "        if i_batch % LOSS_ITER == 0:\n",
    "            # Plotting loss\n",
    "            tmpLoss = loss.eval(fd)\n",
    "            trainPlot.updateCost(tmpLoss, i_batch // LOSS_ITER)\n",
    "    \n",
    "        if i_batch % TEST_ITER == 0:\n",
    "            # Plotting accuracy\n",
    "            fd_test = test_iterator.next_feed(BATCH_SIZE)\n",
    "            accTest = accuracy.eval(fd_test)\n",
    "            accTrain = accuracy.eval(fd)\n",
    "            trainPlot.updateAcc(accTest, accTrain, i_batch // TEST_ITER)\n",
    "\n",
    "        if i_batch % SAVE_ITER == 0:\n",
    "            # TODO Implement saver\n",
    "            pass\n",
    "        \n",
    "        if i_batch % EPOCH == 0:\n",
    "            fd_test = test_iterator.next_feed(BATCH_SIZE)\n",
    "            print('batch %r - loss: %r' % (i_batch, sess.run(loss, fd_test)))\n",
    "            predict_ = sess.run(decoder_prediction, fd_test)\n",
    "            for i, (inp, pred) in enumerate(zip(fd_test[decoder_targets].T, predict_.T)):\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 0:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # TODO add saving on interrup\n",
    "    print('Training interrupted.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
